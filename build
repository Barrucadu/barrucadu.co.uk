#!/usr/bin/env python3

"""build

Usage:
  build [--out=<dir>] [--root=<url>]
  build (-h | --help)

Options:
  -h --help       Show this screen.
  --out=<dir>     Directory to generate site in [default: _site]
  --root=<url>    Root of the website [default: https://www.barrucadu.co.uk/]

"""

import hashlib
import jinja2
import shutil
import sys

from bs4 import BeautifulSoup
from docopt import docopt
from pathlib import Path


FILTERS = {}

args = docopt(__doc__)
OUT_DIR = args["--out"]
BASE_HREF = args["--root"]

JINJA2_ENV = jinja2.Environment(
    autoescape=jinja2.select_autoescape(["html", "xml"]),
    loader=jinja2.FileSystemLoader("_templates"),
)

shutil.rmtree(OUT_DIR, ignore_errors=True)
shutil.copytree("static", OUT_DIR, dirs_exist_ok=True)

HASHED_LINKS = {}
for fpath in Path("hashed-static").iterdir():
    if not fpath.is_file():
        continue

    file_hash = hashlib.sha256()
    with fpath.open(mode="rb") as f:
        while True:
            data = f.read(65536)
            if not data:
                break
            file_hash.update(data)

    HASHED_LINKS[fpath.name] = f"{fpath.stem}-sha256-{file_hash.hexdigest()}{fpath.suffix}"
    shutil.copy(fpath, Path(OUT_DIR, HASHED_LINKS[fpath.name]))

links_to_check = {}
for root, dirs, files in Path("content").walk():
    target_dir = Path(OUT_DIR, *root.parts[1:])
    for dir in dirs:
        Path(target_dir, dir).mkdir()
    for file in files:
        preamble = {
            "title": "barrucadu",
            "template": "default.html",
        }
        body = []
        in_preamble = True
        for line in Path(root, file).read_text().splitlines():
            if in_preamble:
                if line and line[0] == "%":
                    key, val = line[1:].split("=")
                    preamble[key.strip()] = val.strip()
                else:
                    in_preamble = False
                    body = [line]
            else:
                body.append(line)

        if "filters" in preamble:
            for name in preamble.get("filters", "").split(","):
                body = list(FILTERS[name](body, JINJA2_ENV))

        rendered = JINJA2_ENV.from_string(
            f"{{% extends \"{preamble['template']}\" %}}\n" +
            "\n".join(body),
        ).render(
            **preamble,
            body=body,
            base_href=BASE_HREF,
            hashed_links=HASHED_LINKS,
        )
        Path(target_dir, file).with_suffix(".html").write_text(rendered)

        soup = BeautifulSoup(rendered, features="html.parser")
        links = []
        for tag, attr in [("a", "href"), ("img", "src"), ("link", "href")]:
            for elem in soup.find_all(tag):
                links.append(elem.attrs[attr].split("#")[0])
        links_to_check[Path(*root.parts[1:], file)] = set(links)

any_broken_links = False
for page, links in links_to_check.items():
    for link in links:
        # cv.pdf is generated and copied over in the deployment script
        if "://" in link or link in ["mailto:mike@barrucadu.co.uk", "cv.pdf"]:
            continue

        file_destination = Path(OUT_DIR, link)
        dir_destination = Path(OUT_DIR, link, "index.html")
        if file_destination.is_file() or dir_destination.is_file():
            continue

        print(f"BROKEN LINK {page}: {link}", file=sys.stderr)
        any_broken_links = True

if any_broken_links:
    sys.exit(1)
